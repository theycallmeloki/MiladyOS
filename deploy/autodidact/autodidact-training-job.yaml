apiVersion: batch/v1
kind: Job
metadata:
  name: autodidact-training
  namespace: autodidact
spec:
  template:
    spec:
      runtimeClassName: nvidia
      nodeSelector:
        kubernetes.io/hostname: talos-dkp-mps
      initContainers:
      - name: setup-files
        image: busybox
        command:
        - "/bin/sh"
        - "-c"
        - |
          # Copy all necessary files to the app directory
          cp /source-files/UnslothGRPOTrainerTemp.py /app/
          cp /source-files/rl_helpers.py /app/
          cp /source-files/search_module.py /app/
          cp /source-files/embeddings.py /app/
          cp /source-files/training-script.py /app/
          
          # Ensure proper permissions
          chmod 755 /app/*.py
        volumeMounts:
        - name: autodidact-pvc
          mountPath: /app
        - name: all-files
          mountPath: /source-files
      containers:
      - name: training
        image: nvcr.io/nvidia/pytorch:23.10-py3
        resources:
          limits:
            nvidia.com/gpu: 1
            memory: "64Gi"
            cpu: "16"
          requests:
            memory: "48Gi"
            cpu: "8"
        securityContext:
          privileged: true
        command:
        - "/bin/bash"
        - "-c"
        - |
          # Explicitly set the CUDA device to GPU 0
          export CUDA_VISIBLE_DEVICES=0
          export PYTHONPATH="${PYTHONPATH}:/app"
          # Set expanded segments to true to avoid fragmentation
          export PYTORCH_CUDA_ALLOC_CONF="max_split_size_mb:512,expandable_segments:True"
          # Enable TF32 precision for faster training
          export NVIDIA_TF32_OVERRIDE=1
          
          # Check directories and create if needed
          for dir in /app/data /app/saved_data /app/faiss_index /app/model_output; do
            if [ ! -d "$dir" ]; then
              echo "Creating directory: $dir"
              mkdir -p "$dir"
            else
              echo "Directory already exists: $dir"
            fi
          done
          
          # Install UV, setuptools and wandb for training
          pip install --quiet --no-cache-dir uv setuptools wandb datasets
          
          # Check NVIDIA GPU availability
          nvidia-smi || echo "WARNING: No GPU detected!"
          
          # Check if questions.json file exists from previous job
          if [ ! -f "/app/saved_data/questions.json" ]; then
            echo "Error: questions.json not found. The QA job must run first."
            exit 1
          fi
          
          # Go to app directory
          cd /app
          
          # Print Python module search paths
          python -c "import sys; print('Python module search paths:'); [print(p) for p in sys.path]"
          
          # Install wandb directly first using uv with system flag
          echo "Installing wandb and datasets with uv --system..."
          uv pip install --system wandb datasets
          
          # Run the script directly with uv (which installs dependencies from script metadata)
          echo "Starting training with UV..."
          # Reduce batch size to avoid OOM errors
          uv run training-script.py --batch-size=4 --gradient-accumulation-steps=2
        volumeMounts:
        - name: autodidact-pvc
          mountPath: /app/data
          subPath: data
        - name: autodidact-pvc
          mountPath: /app/saved_data
          subPath: saved_data
        - name: autodidact-pvc
          mountPath: /app/faiss_index
          subPath: faiss_index
        - name: autodidact-pvc
          mountPath: /app/model_output
          subPath: model_output
        - name: autodidact-pvc
          mountPath: /app
        - name: dev
          mountPath: /dev
        - name: shm
          mountPath: /dev/shm
      volumes:
      - name: autodidact-pvc
        persistentVolumeClaim:
          claimName: autodidact-data
      - name: all-files
        configMap:
          name: autodidact-all-files
      - name: dev
        hostPath:
          path: /dev
      - name: shm
        emptyDir:
          medium: Memory
          sizeLimit: "24Gi"
      restartPolicy: OnFailure
  backoffLimit: 2